{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction\n",
    "\n",
    "作業檔案：\n",
    "- hw3.ipynb\n",
    "\n",
    "資料：\n",
    "https://www.sharecast.com/index/SP_500/prices/download\n",
    "\n",
    "- train.csv: S&P 500 訓練資料(2009-2017)\n",
    "- test.csv: S&P 500 測試資料(2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "drop_col_names = ['Date'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "0      902.99       931.80      934.73     899.35  4048270080   \n",
      "1      929.17       927.45      936.63     919.53  5413910016   \n",
      "2      931.17       934.70      943.85     927.28  5392620032   \n",
      "3      927.45       906.65      927.45     902.37  4704940032   \n",
      "4      905.73       909.73      910.00     896.81  4991549952   \n",
      "\n",
      "   Tomorrow Movement  \n",
      "0                0.0  \n",
      "1                1.0  \n",
      "2                0.0  \n",
      "3                1.0  \n",
      "4                0.0  \n",
      "      Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "2259     2684.22      2683.34     2685.35    2678.13  1383888512   \n",
      "2260     2679.09      2680.50     2682.74    2677.96  1103808384   \n",
      "2261     2682.10      2682.62     2685.64    2678.91  1149108352   \n",
      "2262     2686.10      2687.54     2687.66    2682.69  1126089856   \n",
      "2263     2689.15      2673.61     2692.12    2673.61  1332374016   \n",
      "\n",
      "      Tomorrow Movement  \n",
      "2259                0.0  \n",
      "2260                1.0  \n",
      "2261                1.0  \n",
      "2262                0.0  \n",
      "2263                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with the previous days as the training target\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !--- You can add your own data preprocessing here ---!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 6)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(2263,)\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(251, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n",
      "(251,)\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "train_x_df = train_df.drop(columns=['Tomorrow Movement'])\n",
    "train_y_df = train_df['Tomorrow Movement']\n",
    "\n",
    "test_x_df = test_df.drop(columns=['Tomorrow Movement'])\n",
    "test_y_df = test_df['Tomorrow Movement']\n",
    "\n",
    "print(train_x_df.shape)\n",
    "print(train_x_df.head())\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())\n",
    "print('-----')\n",
    "print(test_x_df.shape)\n",
    "print(test_x_df.head())\n",
    "print(test_y_df.shape)\n",
    "print(test_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price    Volume\n",
      "0   -1.552572    -1.494607   -1.505683  -1.541181  0.813175\n",
      "1   -1.498571    -1.503581   -1.501760  -1.499581  1.823826\n",
      "2   -1.494446    -1.488625   -1.486853  -1.483605  1.808070\n",
      "3   -1.502119    -1.546489   -1.520714  -1.534956  1.299148\n",
      "4   -1.546921    -1.540136   -1.556744  -1.546417  1.511255\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "# !--- Modify here if you want ---!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_df)\n",
    "\n",
    "normalized_train_x_df = scaler.transform(train_x_df)\n",
    "normalized_train_x_df = np.transpose(normalized_train_x_df)\n",
    "\n",
    "normalized_train_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_train_x_df[0],\n",
    "    'Close Price': normalized_train_x_df[1],\n",
    "    'High Price': normalized_train_x_df[2],\n",
    "    'Low Price': normalized_train_x_df[3],\n",
    "    'Volume': normalized_train_x_df[4],\n",
    "})\n",
    "\n",
    "normalized_test_x_df = scaler.transform(test_x_df)\n",
    "normalized_test_x_df = np.transpose(normalized_test_x_df)\n",
    "normalized_test_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_test_x_df[0],\n",
    "    'Close Price': normalized_test_x_df[1],\n",
    "    'High Price': normalized_test_x_df[2],\n",
    "    'Low Price': normalized_test_x_df[3],\n",
    "    'Volume': normalized_test_x_df[4],\n",
    "})\n",
    "\n",
    "print(normalized_train_x_df.head())\n",
    "print(train_y_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5475033141847105\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict using Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression() # !--- Initialize the model here ---!\n",
    "lr_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "lr_training_acc = accuracy_score(train_y_df, lr_model.predict(normalized_train_x_df))\n",
    "print(lr_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "lr_predict_test_result = lr_model.predict(normalized_test_x_df)\n",
    "lr_testing_acc = accuracy_score(test_y_df, lr_predict_test_result)\n",
    "print(lr_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.5137282196515144, 0.5258964143426295, 0.3694764768608263, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(1, 118, 1, 131)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, lr_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, lr_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5483870967741935\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict with SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC() # !--- Initialize the model here ---!\n",
    "svc_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "svc_training_acc = accuracy_score(train_y_df, svc_model.predict(normalized_train_x_df))\n",
    "print(svc_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "svc_predict_test_result = svc_model.predict(normalized_test_x_df)\n",
    "svc_testing_acc = accuracy_score(test_y_df, svc_predict_test_result)\n",
    "print(svc_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(svc_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.2765670386184346, 0.5258964143426295, 0.3624977895207681, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(0, 119, 0, 132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, svc_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, svc_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 2)\n",
      "   0  1\n",
      "0  1  0\n",
      "1  0  1\n",
      "2  1  0\n",
      "3  0  1\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "# Define NN output groundtruth\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(train_y_df == 0, 1, 0)[:])\n",
    "train_y_df = pd.DataFrame(data=np.where(train_y_df == 0, 0, 1)[:])\n",
    "train_y_df = pd.concat( [ falling_prob, train_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(test_y_df == 0, 1, 0)[:])\n",
    "test_y_df = pd.DataFrame(data=np.where(test_y_df == 0, 0, 1)[:])\n",
    "test_y_df = pd.concat( [ falling_prob, test_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - loss:274.3577880859\n",
      "epoch:100 - loss:273.2029113770\n",
      "epoch:200 - loss:273.8069763184\n",
      "epoch:300 - loss:274.6744384766\n",
      "epoch:400 - loss:275.1631164551\n",
      "epoch:500 - loss:275.3442077637\n",
      "epoch:600 - loss:275.3917846680\n",
      "epoch:700 - loss:275.3905029297\n",
      "epoch:800 - loss:275.3715209961\n",
      "epoch:900 - loss:275.3464355469\n"
     ]
    }
   ],
   "source": [
    "# Define NN structure\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !--- You can modify the NN structure here ---!\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        acti_out = F.relu(h)\n",
    "        y_pred = self.linear2(h)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N = batch size, D_in = input size, H = hidden size, D_out = output size\n",
    "N, D_in, H, D_out = 200, 5, 200, 2  # !--- You can modify here ---!\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum') # !--- You can modify here ---!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # !--- You can modify here ---!\n",
    "\n",
    "\n",
    "# Train NN\n",
    "# !--- You can modify here ---!\n",
    "\n",
    "for t in range(1000):\n",
    "    for batch_num in range(N, len(normalized_train_x_df), N): \n",
    "        y_pred = model(torch.tensor(normalized_train_x_df[batch_num-N:batch_num].values.astype(np.float32))) # !-- Fill the training batch data here --!\n",
    "        loss = criterion(y_pred,torch.tensor(train_y_df[batch_num-N:batch_num].values.astype(np.float32))) # !-- Fill the prediction & groundtruth here to calculate loss --!\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%100 == 0):\n",
    "        print('epoch:%d - loss:%.10f' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5475033141847105\n",
      "\n",
      "testing accuracy:\n",
      "0.5219123505976095\n",
      "\n",
      "predicted testing prob:\n",
      "tensor([[-0.2301,  0.2287],\n",
      "        [-0.2303,  0.2283],\n",
      "        [-0.2762,  0.2734],\n",
      "        [-0.2365,  0.2354],\n",
      "        [-0.2627,  0.2618],\n",
      "        [-0.2886,  0.2860],\n",
      "        [-0.2740,  0.2736],\n",
      "        [-0.2334,  0.2316],\n",
      "        [-0.2341,  0.2320],\n",
      "        [-0.3801,  0.3782],\n",
      "        [-0.2328,  0.2313],\n",
      "        [-0.3151,  0.3136],\n",
      "        [-0.2782,  0.2771],\n",
      "        [-0.2045,  0.2027],\n",
      "        [-0.2871,  0.2854],\n",
      "        [-0.3291,  0.3282],\n",
      "        [-0.3273,  0.3265],\n",
      "        [-0.2044,  0.2026],\n",
      "        [-0.3482,  0.3461],\n",
      "        [-0.3429,  0.3408],\n",
      "        [-0.3430,  0.3418],\n",
      "        [-0.2912,  0.2872],\n",
      "        [-0.4639,  0.4628],\n",
      "        [-0.6151,  0.6120],\n",
      "        [-0.0017,  0.0029],\n",
      "        [-0.3487,  0.3398],\n",
      "        [-0.6475,  0.6468],\n",
      "        [-0.1939,  0.2024],\n",
      "        [-0.2117,  0.2096],\n",
      "        [-0.2053,  0.2044],\n",
      "        [-0.1007,  0.0988],\n",
      "        [-0.1992,  0.2022],\n",
      "        [-0.2761,  0.2704],\n",
      "        [-0.3040,  0.3015],\n",
      "        [-0.3562,  0.3494],\n",
      "        [-0.3057,  0.3013],\n",
      "        [-0.1524,  0.1510],\n",
      "        [-0.2022,  0.2009],\n",
      "        [-0.4193,  0.4161],\n",
      "        [-0.4359,  0.4330],\n",
      "        [-0.4131,  0.4123],\n",
      "        [-0.1541,  0.1537],\n",
      "        [-0.1298,  0.1277],\n",
      "        [-0.2801,  0.2814],\n",
      "        [-0.2143,  0.2135],\n",
      "        [-0.2523,  0.2523],\n",
      "        [-0.1571,  0.1555],\n",
      "        [-0.3195,  0.3172],\n",
      "        [-0.3795,  0.3774],\n",
      "        [-0.3678,  0.3667],\n",
      "        [-0.3064,  0.3042],\n",
      "        [-0.3432,  0.3391],\n",
      "        [-0.3626,  0.3649],\n",
      "        [-0.2793,  0.2771],\n",
      "        [-0.3003,  0.2944],\n",
      "        [-0.4468,  0.4452],\n",
      "        [-0.4767,  0.4741],\n",
      "        [-0.1143,  0.1157],\n",
      "        [-0.4503,  0.4512],\n",
      "        [-0.3065,  0.3031],\n",
      "        [-0.1796,  0.1754],\n",
      "        [-0.4217,  0.4254],\n",
      "        [-0.1720,  0.1729],\n",
      "        [-0.0223,  0.0219],\n",
      "        [-0.2516,  0.2498],\n",
      "        [-0.3906,  0.3911],\n",
      "        [-0.2856,  0.2775],\n",
      "        [-0.2084,  0.2056],\n",
      "        [-0.2755,  0.2711],\n",
      "        [-0.2396,  0.2359],\n",
      "        [-0.3274,  0.3277],\n",
      "        [-0.2426,  0.2403],\n",
      "        [-0.2286,  0.2257],\n",
      "        [-0.2888,  0.2866],\n",
      "        [-0.3066,  0.3068],\n",
      "        [-0.3565,  0.3566],\n",
      "        [-0.2813,  0.2808],\n",
      "        [-0.4209,  0.4227],\n",
      "        [-0.2444,  0.2462],\n",
      "        [-0.2310,  0.2283],\n",
      "        [-0.2925,  0.2927],\n",
      "        [-0.3780,  0.3750],\n",
      "        [-0.2210,  0.2229],\n",
      "        [-0.3482,  0.3461],\n",
      "        [-0.2511,  0.2548],\n",
      "        [-0.0973,  0.0956],\n",
      "        [-0.2624,  0.2596],\n",
      "        [-0.2648,  0.2653],\n",
      "        [-0.2032,  0.2017],\n",
      "        [-0.2054,  0.2033],\n",
      "        [-0.2537,  0.2521],\n",
      "        [-0.2881,  0.2856],\n",
      "        [-0.2977,  0.2980],\n",
      "        [-0.2406,  0.2379],\n",
      "        [-0.2761,  0.2738],\n",
      "        [-0.2985,  0.2971],\n",
      "        [-0.2553,  0.2524],\n",
      "        [-0.3316,  0.3298],\n",
      "        [-0.2079,  0.2070],\n",
      "        [-0.2753,  0.2775],\n",
      "        [-0.2773,  0.2763],\n",
      "        [-0.3282,  0.3282],\n",
      "        [-0.1997,  0.1970],\n",
      "        [-0.3594,  0.3583],\n",
      "        [-0.2218,  0.2196],\n",
      "        [-0.2659,  0.2639],\n",
      "        [-0.2790,  0.2783],\n",
      "        [-0.2117,  0.2108],\n",
      "        [-0.2990,  0.2983],\n",
      "        [-0.2274,  0.2260],\n",
      "        [-0.2812,  0.2778],\n",
      "        [-0.2799,  0.2789],\n",
      "        [-0.3466,  0.3443],\n",
      "        [-0.2972,  0.2954],\n",
      "        [-0.3261,  0.3264],\n",
      "        [-0.2496,  0.2494],\n",
      "        [-0.2433,  0.2428],\n",
      "        [-0.3032,  0.3010],\n",
      "        [-0.3511,  0.3505],\n",
      "        [-0.3433,  0.3410],\n",
      "        [-0.3612,  0.3635],\n",
      "        [-0.2868,  0.2844],\n",
      "        [-0.3882,  0.3834],\n",
      "        [-0.2110,  0.2090],\n",
      "        [-0.3258,  0.3210],\n",
      "        [-0.1818,  0.1813],\n",
      "        [-0.3138,  0.3123],\n",
      "        [-0.2177,  0.2175],\n",
      "        [-0.1768,  0.1751],\n",
      "        [-0.2192,  0.2174],\n",
      "        [-0.2599,  0.2582],\n",
      "        [-0.3020,  0.2997],\n",
      "        [-0.2255,  0.2239],\n",
      "        [-0.2630,  0.2616],\n",
      "        [-0.2919,  0.2907],\n",
      "        [-0.2069,  0.2042],\n",
      "        [-0.2719,  0.2709],\n",
      "        [-0.3123,  0.3109],\n",
      "        [-0.3065,  0.3040],\n",
      "        [-0.2536,  0.2523],\n",
      "        [-0.2958,  0.2940],\n",
      "        [-0.1929,  0.1905],\n",
      "        [-0.3092,  0.3056],\n",
      "        [-0.3682,  0.3685],\n",
      "        [-0.3462,  0.3448],\n",
      "        [-0.2837,  0.2804],\n",
      "        [-0.3208,  0.3196],\n",
      "        [-0.1821,  0.1806],\n",
      "        [-0.2458,  0.2444],\n",
      "        [-0.2431,  0.2416],\n",
      "        [-0.2822,  0.2794],\n",
      "        [-0.2793,  0.2773],\n",
      "        [-0.2993,  0.2968],\n",
      "        [-0.3036,  0.3028],\n",
      "        [-0.3305,  0.3277],\n",
      "        [-0.2360,  0.2339],\n",
      "        [-0.3165,  0.3179],\n",
      "        [-0.2599,  0.2561],\n",
      "        [-0.2413,  0.2393],\n",
      "        [-0.2717,  0.2700],\n",
      "        [-0.2906,  0.2868],\n",
      "        [-0.2774,  0.2754],\n",
      "        [-0.2917,  0.2889],\n",
      "        [-0.2328,  0.2307],\n",
      "        [-0.2454,  0.2431],\n",
      "        [-0.2972,  0.2957],\n",
      "        [-0.2334,  0.2315],\n",
      "        [-0.3113,  0.3100],\n",
      "        [-0.2762,  0.2747],\n",
      "        [-0.2883,  0.2881],\n",
      "        [-0.3038,  0.3037],\n",
      "        [-0.3225,  0.3222],\n",
      "        [-0.2789,  0.2755],\n",
      "        [-0.3017,  0.2990],\n",
      "        [-0.2204,  0.2186],\n",
      "        [-0.2893,  0.2881],\n",
      "        [-0.2719,  0.2695],\n",
      "        [-0.2894,  0.2890],\n",
      "        [-0.3359,  0.3346],\n",
      "        [-0.2418,  0.2386],\n",
      "        [-0.2919,  0.2896],\n",
      "        [-0.2644,  0.2615],\n",
      "        [-0.4001,  0.3972],\n",
      "        [-0.3091,  0.3080],\n",
      "        [-0.3225,  0.3205],\n",
      "        [-0.3391,  0.3350],\n",
      "        [-0.2866,  0.2826],\n",
      "        [-0.2906,  0.2878],\n",
      "        [-0.3088,  0.3060],\n",
      "        [-0.3029,  0.3002],\n",
      "        [-0.3217,  0.3190],\n",
      "        [-0.3431,  0.3448],\n",
      "        [-0.3394,  0.3395],\n",
      "        [-0.2557,  0.2560],\n",
      "        [-0.3079,  0.3048],\n",
      "        [-0.5984,  0.5975],\n",
      "        [-0.4677,  0.4663],\n",
      "        [-0.2841,  0.2888],\n",
      "        [-0.3301,  0.3265],\n",
      "        [-0.1203,  0.1178],\n",
      "        [-0.2757,  0.2784],\n",
      "        [-0.3924,  0.3929],\n",
      "        [-0.3242,  0.3197],\n",
      "        [-0.3454,  0.3442],\n",
      "        [-0.2028,  0.2044],\n",
      "        [-0.5723,  0.5712],\n",
      "        [-0.1831,  0.1794],\n",
      "        [-0.3233,  0.3229],\n",
      "        [-0.4003,  0.4020],\n",
      "        [-0.1549,  0.1534],\n",
      "        [-0.3092,  0.3022],\n",
      "        [-0.2124,  0.2119],\n",
      "        [-0.3633,  0.3640],\n",
      "        [-0.2361,  0.2349],\n",
      "        [-0.2185,  0.2167],\n",
      "        [-0.1427,  0.1405],\n",
      "        [-0.2884,  0.2873],\n",
      "        [-0.3344,  0.3360],\n",
      "        [-0.4464,  0.4455],\n",
      "        [-0.3219,  0.3169],\n",
      "        [-0.4048,  0.4048],\n",
      "        [-0.1347,  0.1365],\n",
      "        [-0.2327,  0.2300],\n",
      "        [-0.4166,  0.4168],\n",
      "        [-0.3429,  0.3404],\n",
      "        [-0.3067,  0.3026],\n",
      "        [-0.2404,  0.2367],\n",
      "        [-0.1925,  0.1907],\n",
      "        [-0.2029,  0.2028],\n",
      "        [-0.0774,  0.0770],\n",
      "        [-0.2731,  0.2711],\n",
      "        [-0.2297,  0.2285],\n",
      "        [-0.3022,  0.3017],\n",
      "        [-0.5747,  0.5735],\n",
      "        [-0.5766,  0.5754],\n",
      "        [-0.1497,  0.1562],\n",
      "        [-0.4707,  0.4683],\n",
      "        [-0.2173,  0.2235],\n",
      "        [-0.3612,  0.3610],\n",
      "        [-0.3195,  0.3127],\n",
      "        [-0.3049,  0.3037],\n",
      "        [-0.3826,  0.3814],\n",
      "        [-0.4251,  0.4250],\n",
      "        [-0.3231,  0.3224],\n",
      "        [-0.4257,  0.4207],\n",
      "        [-0.3868,  0.3882],\n",
      "        [-0.5110,  0.5035],\n",
      "        [-0.3944,  0.3920],\n",
      "        [ 0.1687, -0.1666],\n",
      "        [-0.0373,  0.0450],\n",
      "        [-0.2979,  0.2951]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "predicted testing labels:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "nn_predict_train_y = model(torch.tensor(normalized_train_x_df.values.astype(np.float32))) # !-- Predict training data here --!\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(train_y_df[0], result_train))\n",
    "\n",
    "nn_predict_test_y = model(torch.tensor(normalized_test_x_df.values.astype(np.float32))) # !-- Predict training data here --!\n",
    "result_test = np.where(nn_predict_test_y[:, 0] > nn_predict_test_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(test_y_df[0], result_test))\n",
    "\n",
    "print('\\npredicted testing prob:')\n",
    "print(nn_predict_test_y)\n",
    "print('\\npredicted testing labels:')\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision, recall, fbeta-score:\n",
      "(0.27556972111553785, 0.5219123505976095, 0.3606933522454684, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(131, 1, 119, 0)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('\\nprecision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df[0], result_test, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df[0], result_test).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    這三個 model 的 training accuracy 以及 testing accuracy 大概都只有百分之五十幾的正確率，調過幾個參數後結果也都差不多， Neural Network 有時候我改參數會出現錯誤訊息，有時候還會跑不完，所以最後我只用了最保守的 N, D_in, H, D_out = 200, 5, 200, 2 參數，有比助教的好一點點。連 training accuracy 都只有 0.5 左右，推測應該是 under fitting，而且其實隨機亂猜就是 0.5，所以可能真的是股票真的很難用這種方法，這一些 feature 去預測漲跌，想想也有道理，如果股票真的可以預測精準的話，大家就都來玩股票就可以發大財了，這顯然是不太可能發生的事。\n",
    "    \n",
    "    也感謝助教教我 PyTorch 的安裝方法，我本來裝錯一直鬼打牆。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
